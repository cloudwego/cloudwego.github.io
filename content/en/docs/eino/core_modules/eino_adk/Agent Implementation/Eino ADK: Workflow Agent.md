---
Description: ""
date: "2025-07-22"
lastmod: ""
tags: []
title: 'Eino ADK: Workflow Agent'
weight: 0
---

WorkflowAgent supports running multiple Agents in a static mode. "Static" means that the collaboration flow between Agents (such as sequence, parallelism) is predefined in code, rather than dynamically decided by Agents at runtime. Eino ADK provides three basic Workflow Agents: Sequential, Parallel, Loop, which can be nested with each other to complete more complex tasks.

By default, the input for each Agent in the Workflow is generated using the method introduced in the History section. You can customize the AgentInput generation method through WithHistoryRewriter.

When an Agent produces an ExitAction Event, the Workflow Agent will exit immediately, regardless of whether there are other Agents that need to run afterward.

# SequentialAgent

SequentialAgent will execute a series of Agents sequentially in the order you provide:

![](/img/eino/sequential_agents.png)

We'll introduce the usage of SequentialAgent through a Research Agent containing two sub-Agents, where the first Plan Agent will receive a research topic and generate a research plan; the second Write Agent will receive the research topic and the research plan generated by Plan (the Write Agent's input is generated according to the default method introduced in the History section, or can be customized through WithHistoryRewriter), and write a report.

First, create two sub-Agents. We simplify both Agents to contain only ChatModel. In practice, you can enhance the Agents' plan and write capabilities by adding Tools:

```go
import (
    "context"
    "log"
    "os"

    "github.com/cloudwego/eino-ext/components/model/openai"
    "github.com/cloudwego/eino/adk"
    "github.com/cloudwego/eino/components/model"
)

func newChatModel() model.ToolCallingChatModel {
    cm, err := openai.NewChatModel(context.Background(), &openai.ChatModelConfig{
       APIKey: os.Getenv("OPENAI_API_KEY"),
       Model:  os.Getenv("OPENAI_MODEL"),
    })
    if err != nil {
       log.Fatal(err)
    }
    return cm
}

func NewPlanAgent() adk.Agent {
    a, err := adk.NewChatModelAgent(context.Background(), &adk.ChatModelAgentConfig{
       Name:        "PlannerAgent",
       Description: "Generates a research plan based on a topic.",
       Instruction: `
You are an expert research planner. 
Your goal is to create a comprehensive, step-by-step research plan for a given topic. 
The plan should be logical, clear, and easy to follow.
The user will provide the research topic. Your output must ONLY be the research plan itself, without any conversational text, introductions, or summaries.`,
       Model: newChatModel(),
    })
    if err != nil {
       log.Fatal(err)
    }
    return a
}

func NewWriterAgent() adk.Agent {
    a, err := adk.NewChatModelAgent(context.Background(), &adk.ChatModelAgentConfig{
       Name:        "WriterAgent",
       Description: "Writes a report based on a research plan.",
       Instruction: `
You are an expert academic writer.
You will be provided with a detailed research plan.
Your task is to expand on this plan to write a comprehensive, well-structured, and in-depth report.
The user will provide the research plan. Your output should be the complete final report.`,
       Model: newChatModel(),
    })
    if err != nil {
       log.Fatal(err)
    }
    return a
}
```

Then use Sequential Agent to orchestrate the two sub-Agents:

```go
import (
    "context"
    "fmt"
    "log"
    "os"

    "github.com/cloudwego/eino/adk"

    "github.com/cloudwego/eino-examples/adk/intro/workflow/sequential/internal"
)

func main() {
    ctx := context.Background()

    a, err := adk.NewSequentialAgent(ctx, &adk.SequentialAgentConfig{
       Name:        "ResearchAgent",
       Description: "A sequential workflow for planning and writing a research report.",
       SubAgents:   []adk.Agent{internal.NewPlanAgent(), internal.NewWriterAgent()},
    })
    if err != nil {
       log.Fatal(err)
    }

    runner := adk.NewRunner(ctx, adk.RunnerConfig{
       Agent: a,
    })

    iter := runner.Query(ctx, "The history of Large Language Models")
    for {
       event, ok := iter.Next()
       if !ok {
          break
       }
       if event.Err != nil {
          fmt.Printf("Error: %v\n", event.Err)
          break
       }
       msg, err := event.Output.MessageOutput.GetMessage()
       if err != nil {
          log.Fatal(err)
       }
       fmt.Printf("Agent[%s]:\n %+v\n\n===========\n\n", event.AgentName, msg)
    }
}
```

The execution result is as follows:

```
Agent[PlannerAgent]:
 assistant: Step 1: Define the Research Scope
- Determine the time frame for your historical analysis, starting from the early development of large language models (LLMs) to the present.

......

Step 10: Update and Revise
- Plan for periodic updates to incorporate new developments in large language models as they arise.
- Keep abreast of publications and ongoing research in the field to maintain the relevance and accuracy of your research.
finish_reason: stop
usage: &{86 675 761}

===========

Agent[WriterAgent]:
 assistant: # The History of Large Language Models

## Introduction

The development of Large Language Models (LLMs) marks a significant milestone in the field of artificial intelligence (AI) and natural language processing (NLP). These models, capable of understanding and generating human-like text, have evolved rapidly over the past few decades, showcasing profound improvements in language comprehension and generation. This report explores the history of LLMs, tracing their evolution from early linguistic theories to the sophisticated models we see today.

## Early Foundations in Linguistics and Computation

......

## Conclusion

The history of Large Language Models is a testament to the rapid evolution of artificial intelligence. From early linguistic theories and basic neural networks to sophisticated models capable of human-like language generation, each milestone has contributed to our current understanding and capabilities. As LLMs continue to advance, their potential to transform industries, improve communication, and enable new technologies remains vast. However, it is crucial that ethical considerations keep pace with technological advances to ensure these models benefit society at large.

---

This comprehensive overview of the history of Large Language Models outlines their origins, evolution, and impact, providing a foundation for further exploration and research in this dynamic field.
finish_reason: stop
usage: &{74 1066 1140}

===========
```

# LoopAgent

LoopAgent is implemented based on SequentialAgent. After SequentialAgent completes execution, it runs again from the beginning:

![](/img/eino/loop_agents.png)

LoopAgent exits when an Agent produces an ExitAction Event, or you can configure MaxIteration to control the maximum number of loops. Create using adk.NewLoopAgent:

```
adk.NewLoopAgent(ctx, &adk.LoopAgentConfig{
    Name:          "name",
    Description:   "description",
    SubAgents:     []adk.Agent{a1,a2},
    MaxIterations: 3,
})
```

# ParallelAgent

ParallelAgent will run several Agents concurrently:

![](/img/eino/parallel_agents.png)

Create using adk.NewParallelAgent:

```
adk.NewParallelAgent(ctx, &adk.ParallelAgentConfig{
    Name:        "name",
    Description: "desc",
    SubAgents:   []adk.Agent{a1,a2},
})
```