---
Description: ""
date: "2025-12-03"
lastmod: ""
tags: []
title: ChatModel - Ollama
weight: 0
---

# Ollama æ¨¡å‹

ä¸€ä¸ªé’ˆå¯¹ [Eino](https://github.com/cloudwego/eino) çš„ Ollama æ¨¡å‹å®ç°ï¼Œå®ç°äº† `ToolCallingChatModel` æ¥å£ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿä¸ Eino çš„ LLM åŠŸèƒ½æ— ç¼é›†æˆï¼Œä»¥å¢å¼ºè‡ªç„¶è¯­è¨€å¤„ç†å’Œç”Ÿæˆèƒ½åŠ›ã€‚

## ç‰¹æ€§

- å®ç°äº† `github.com/cloudwego/eino/components/model.Model`
- è½»æ¾ä¸ Eino çš„æ¨¡å‹ç³»ç»Ÿé›†æˆ
- å¯é…ç½®çš„æ¨¡å‹å‚æ•°
- æ”¯æŒèŠå¤©è¡¥å…¨
- æ”¯æŒæµå¼å“åº”
- æ”¯æŒè‡ªå®šä¹‰å“åº”è§£æ
- çµæ´»çš„æ¨¡å‹é…ç½®

## å®‰è£…

```bash
go get github.com/cloudwego/eino-ext/components/model/ollama@latest
```

## å¿«é€Ÿå¼€å§‹

ä»¥ä¸‹æ˜¯å¦‚ä½•ä½¿ç”¨ Ollama æ¨¡å‹çš„å¿«é€Ÿç¤ºä¾‹ï¼š

```go
package main

import (
        "context"
        "log"
        "os"

        "github.com/cloudwego/eino/schema"

        "github.com/cloudwego/eino-ext/components/model/ollama"
)

func main() {
        ctx := context.Background()
        modelName := os.Getenv("MODEL_NAME")
        
        chatModel, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
                BaseURL: "http://localhost:11434",
                Model:   modelName,
        })
        if err != nil {
                log.Printf("NewChatModel failed, err=%v\n", err)
                return
        }

        resp, err := chatModel.Generate(ctx, []*schema.Message{
                {
                        Role:    schema.User,
                        Content: "as a machine, how do you answer user's question?",
                },
        })
        if err != nil {
                log.Printf("Generate failed, err=%v\n", err)
                return
        }

        log.Printf("output: \n%v\n", resp)
}
```

## é…ç½®

å¯ä»¥ä½¿ç”¨ `ollama.ChatModelConfig` ç»“æ„ä½“é…ç½®æ¨¡å‹ï¼š

```go
type ChatModelConfig struct {
    BaseURL string        `json:"base_url"`
    Timeout time.Duration `json:"timeout"` // request timeout for http client
    
    // HTTPClient specifies the client to send HTTP requests.
    // If HTTPClient is set, Timeout will not be used.
    // Optional. Default &http.Client{Timeout: Timeout}
    HTTPClient *http.Client `json:"http_client"`
    
    Model     string          `json:"model"`
    Format    json.RawMessage `json:"format"`
    KeepAlive *time.Duration  `json:"keep_alive"`
    
    Options *Options `json:"options"`
    
    Thinking *ThinkValue `json:"thinking"`
}


type Options struct {
    Runner
    
    // NumKeep specifies the number of tokens from the prompt to retain when the context size is exceeded and tokens need to be trimmed.
    NumKeep int `json:"num_keep,omitempty"`
    // Seed sets the random number seed for the model. Using the same seed with the same parameters will produce the same output.
    Seed int `json:"seed,omitempty"`
    // NumPredict sets the maximum number of tokens to generate.
    NumPredict int `json:"num_predict,omitempty"`
    // TopK controls the diversity of the generated text by limiting the selection of tokens to the top k most likely tokens.
    TopK int `json:"top_k,omitempty"`
    // TopP, also known as nucleus sampling, is another way to control the diversity of the generated text. It filters out the least likely tokens whose cumulative probability is below a certain threshold.
    TopP float32 `json:"top_p,omitempty"`
    // MinP is a parameter that works with TopP to ensure that the generated text is not too constrained. It sets a minimum probability for a token to be considered.
    MinP float32 `json:"min_p,omitempty"`
    // TypicalP is a parameter that helps to generate more "typical" or expected text by sampling from a reduced set of tokens that are considered typical.
    TypicalP float32 `json:"typical_p,omitempty"`
    // RepeatLastN specifies how many of the last N tokens to consider for penalizing repetition.
    RepeatLastN int `json:"repeat_last_n,omitempty"`
    // Temperature controls the randomness of the generated text. A higher temperature results in more random and creative output, while a lower temperature produces more predictable and conservative text.
    Temperature float32 `json:"temperature,omitempty"`
    // RepeatPenalty is used to penalize the model for repeating tokens that have already appeared in the generated text.
    RepeatPenalty float32 `json:"repeat_penalty,omitempty"`
    // PresencePenalty is used to penalize the model for introducing new tokens that were not present in the prompt.
    PresencePenalty float32 `json:"presence_penalty,omitempty"`
    // FrequencyPenalty is used to penalize the model for using tokens that appear frequently in the training data.
    FrequencyPenalty float32 `json:"frequency_penalty,omitempty"`
    // Stop is a list of strings that will cause the generation to stop if they are encountered.
    Stop []string `json:"stop,omitempty"`
}

type ThinkValue struct {
    // Value can be a bool or string
    Value interface{}
}
```

## ç¤ºä¾‹

### æ–‡æœ¬ç”Ÿæˆ

```go
package main

import (
        "context"
        "log"
        "os"

        "github.com/cloudwego/eino/schema"

        "github.com/cloudwego/eino-ext/components/model/ollama"
)

func main() {
        ctx := context.Background()
        modelName := os.Getenv("MODEL_NAME")
        chatModel, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
                BaseURL: "http://localhost:11434",
                Model:   modelName,
        })
        if err != nil {
                log.Printf("NewChatModel failed, err=%v\n", err)
                return
        }

        resp, err := chatModel.Generate(ctx, []*schema.Message{
                {
                        Role:    schema.User,
                        Content: "as a machine, how do you answer user's question?",
                },
        })
        if err != nil {
                log.Printf("Generate failed, err=%v\n", err)
                return
        }

        log.Printf("output: \n%v\n", resp)
}
```

### å¤šæ¨¡æ€æ”¯æŒ(å›¾ç‰‡ç†è§£)

```go
package main

import (
        "context"
        "fmt"
        "log"
        "os"

        "github.com/cloudwego/eino/schema"

        "github.com/cloudwego/eino-ext/components/model/ollama"
)

func main() {
        ctx := context.Background()
        modelName := os.Getenv("MODEL_NAME")
        chatModel, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
                BaseURL: "http://localhost:11434",
                Model:   modelName,
        })
        if err != nil {
                log.Printf("NewChatModel failed, err=%v\n", err)
                return
        }

        multiModalMsg := &schema.Message{
                UserInputMultiContent: []schema.MessageInputPart{
                        {
                                Type: schema.ChatMessagePartTypeText,
                                Text: "this picture is a landscape photo, what's the picture's content",
                        },
                        {
                                Type: schema.ChatMessagePartTypeImageURL,
                                Image: &schema.MessageInputImage{
                                        MessagePartCommon: schema.MessagePartCommon{
                                                URL: of("https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT11qEDxU4X_MVKYQVU5qiAVFidA58f8GG0bQ&s"),
                                        },
                                        Detail: schema.ImageURLDetailAuto,
                                },
                        },
                },
        }

        resp, err := chatModel.Generate(ctx, []*schema.Message{
                multiModalMsg,
        })
        if err != nil {
                log.Fatalf("Generate failed, err=%v", err)
        }

        fmt.Printf("output: \n%v", resp)
}

func of[T any](a T) *T {
        return &a
}
```

### æµå¼ç”Ÿæˆ

```go
package main

import (
        "context"
        "fmt"
        "io"
        "log"
        "os"

        "github.com/cloudwego/eino/schema"

        "github.com/cloudwego/eino-ext/components/model/ollama"
)

func main() {
        ctx := context.Background()
        modelName := os.Getenv("MODEL_NAME")
        chatModel, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
                BaseURL: "http://localhost:11434",
                Model:   modelName,
        })
        if err != nil {
                log.Printf("NewChatModel failed, err=%v\n", err)
                return
        }

        streamMsgs, err := chatModel.Stream(ctx, []*schema.Message{
                {
                        Role:    schema.User,
                        Content: "as a machine, how do you answer user's question?",
                },
        })

        if err != nil {
                log.Printf("Generate failed, err=%v", err)
                return
        }

        defer streamMsgs.Close()

        log.Println("typewriter output:")
        for {
                msg, err := streamMsgs.Recv()
                if err == io.EOF {
                        break
                }
                if err != nil {
                        log.Printf("\nstream.Recv failed, err=%v", err)
                        return
                }
                fmt.Print(msg.Content)
        }

        fmt.Print("\n")
}
```

### å·¥å…·è°ƒç”¨

```go
package main

import (
        "context"
        "log"
        "os"

        "github.com/cloudwego/eino/schema"

        "github.com/cloudwego/eino-ext/components/model/ollama"
)

func main() {

        ctx := context.Background()
        modelName := os.Getenv("MODEL_NAME")
        chatModel, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
                BaseURL: "http://localhost:11434",
                Model:   modelName,
        })
        if err != nil {
                log.Printf("NewChatModel failed, err=%v", err)
                return
        }

        err = chatModel.BindTools([]*schema.ToolInfo{
                {
                        Name: "user_company",
                        Desc: "Query the user's company and position information based on their name and email",
                        ParamsOneOf: schema.NewParamsOneOfByParams(
                                map[string]*schema.ParameterInfo{
                                        "name": {
                                                Type: "string",
                                                Desc: "The user's name",
                                        },
                                        "email": {
                                                Type: "string",
                                                Desc: "The user's email",
                                        },
                                }),
                },
                {
                        Name: "user_salary",
                        Desc: "Query the user's salary information based on their name and email",
                        ParamsOneOf: schema.NewParamsOneOfByParams(
                                map[string]*schema.ParameterInfo{
                                        "name": {
                                                Type: "string",
                                                Desc: "The user's name",
                                        },
                                        "email": {
                                                Type: "string",
                                                Desc: "The user's email",
                                        },
                                }),
                },
        })
        if err != nil {
                log.Printf("BindForcedTools failed, err=%v", err)
                return
        }

        resp, err := chatModel.Generate(ctx, []*schema.Message{
                {
                        Role:    schema.System,
                        Content: "You are a real estate agent. Use the user_company and user_salary APIs to provide relevant property information based on the user's salary and job. Email is required",
                },
                {
                        Role:    schema.User,
                        Content: "My name is zhangsan, and my email is zhangsan@bytedance.com. Please recommend some suitable houses for me.",
                },
        })

        if err != nil {
                log.Printf("Generate failed, err=%v", err)
                return
        }

        log.Printf("output: \n%+v", resp)
}
```

### å¼€å¯ Thinking æ¨¡å¼

```go
package main

import (
        "context"
        "log"
        "os"

        "github.com/cloudwego/eino/schema"
        ollamaapi "github.com/eino-contrib/ollama/api"

        "github.com/cloudwego/eino-ext/components/model/ollama"
)

func main() {
        ctx := context.Background()
        modelName := os.Getenv("MODEL_NAME")
        thinking := ollamaapi.ThinkValue{Value: true}
        chatModel, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
                BaseURL:  "http://localhost:11434",
                Model:    modelName,
                Thinking: &thinking,
        })
        if err != nil {
                log.Printf("NewChatModel failed, err=%v\n", err)
                return
        }

        resp, err := chatModel.Generate(ctx, []*schema.Message{
                {
                        Role:    schema.User,
                        Content: "as a machine, how do you answer user's question?",
                },
        })
        if err != nil {
                log.Printf("Generate failed, err=%v\n", err)
                return
        }

        log.Printf("output thinking: \n%v\n", resp.ReasoningContent)
        log.Printf("output content: \n%v\n", resp.Content)
}
```

## 

## **åŸºæœ¬ä»‹ç»**

~~Ollama æ¨¡å‹æ˜¯ ChatModel æ¥å£çš„ä¸€ä¸ªå®ç°ï¼Œç”¨äºä¸ Ollama æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹æœåŠ¡è¿›è¡Œäº¤äº’ï¼ŒOllama æ˜¯ä¸€ä¸ªå¼€æºçš„æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹è¿è¡Œæ¡†æ¶ï¼Œæ”¯æŒå¤šç§å¼€æºæ¨¡å‹ï¼ˆå¦‚ Llamaã€Mistral ç­‰ï¼‰ï¼Œæä¾›ç®€å•çš„ API æ¥å£å’Œå®Œæ•´çš„æ€§èƒ½ç›‘æ§ã€‚ã€‚è¯¥ç»„ä»¶å®ç°äº† ~~[Eino: ChatModel ä½¿ç”¨è¯´æ˜](/zh/docs/eino/core_modules/components/chat_model_guide)

## **ä½¿ç”¨æ–¹å¼**

### **ç»„ä»¶åˆå§‹åŒ–**

Ollama æ¨¡å‹é€šè¿‡ `NewChatModel` å‡½æ•°è¿›è¡Œåˆå§‹åŒ–ï¼Œä¸»è¦é…ç½®å‚æ•°å¦‚ä¸‹ï¼š

```go
import (
    "github.com/cloudwego/eino-ext/components/model/ollama"
    "github.com/ollama/ollama/api"
)

model, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
    // åŸºç¡€é…ç½®
    BaseURL: "http://localhost:11434", // Ollama æœåŠ¡åœ°å€
    Timeout: 30 * time.Second,         // è¯·æ±‚è¶…æ—¶æ—¶é—´

    // æ¨¡å‹é…ç½®
    Model:     "llama2",   // æ¨¡å‹åç§°
    Format:    json.RawMessage("json"),     // è¾“å‡ºæ ¼å¼ï¼ˆå¯é€‰ï¼‰
    KeepAlive: &keepAlive, // ä¿æŒè¿æ¥æ—¶é—´

    // æ¨¡å‹å‚æ•°
    Options: &api.Options{
       Runner: api.Runner{
          NumCtx:    4096, // ä¸Šä¸‹æ–‡çª—å£å¤§å°
          NumGPU:    1,    // GPU æ•°é‡
          NumThread: 4,    // CPU çº¿ç¨‹æ•°
       },
       Temperature:   0.7,        // æ¸©åº¦
       TopP:          0.9,        // Top-P é‡‡æ ·
       TopK:          40,         // Top-K é‡‡æ ·
       Seed:          42,         // éšæœºç§å­
       NumPredict:    100,        // æœ€å¤§ç”Ÿæˆé•¿åº¦
       Stop:          []string{}, // åœæ­¢è¯
       RepeatPenalty: 1.1,        // é‡å¤æƒ©ç½š
    },
})
```

### **ç”Ÿæˆå¯¹è¯**

å¯¹è¯ç”Ÿæˆæ”¯æŒæ™®é€šæ¨¡å¼å’Œæµå¼æ¨¡å¼ï¼š

```go
// æ™®é€šæ¨¡å¼
response, err := model.Generate(ctx, messages)
    
// æµå¼æ¨¡å¼
stream, err := model.Stream(ctx, messages)
```

æ¶ˆæ¯æ ¼å¼ç¤ºä¾‹ï¼š

```go
import "github.com/cloudwego/eino/schema"

messages := []*schema.Message{
    // ç³»ç»Ÿæ¶ˆæ¯
    schema.SystemMessage("ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"),
        
    // ç”¨æˆ·æ¶ˆæ¯
    schema.UserMessage("ä½ å¥½")
}
```

### **å·¥å…·è°ƒç”¨**

æ”¯æŒç»‘å®šå·¥å…·ï¼š

> æ³¨æ„ï¼Œä»…æœ‰æ”¯æŒ function call çš„æ¨¡å‹æ‰èƒ½ä½¿ç”¨è¿™ä¸ªèƒ½åŠ›

```go
import "github.com/cloudwego/eino/schema"

// å®šä¹‰å·¥å…·
tools := []*schema.ToolInfo{
    {
       Name: "search",
       Desc: "æœç´¢ä¿¡æ¯",
       ParamsOneOf: schema.NewParamsOneOfByParams(map[string]*schema.ParameterInfo{
          "query": {
             Type:     schema.String,
             Desc:     "æœç´¢å…³é”®è¯",
             Required: true,
          },
       }),
    },
}

// ç»‘å®šå·¥å…·
err := model.BindTools(tools)
```

### **å®Œæ•´ä½¿ç”¨ç¤ºä¾‹**

#### **åŸºæœ¬å¯¹è¯**

```go
package main

import (
    "context"
    "time"

    "github.com/cloudwego/eino-ext/components/model/ollama"
    "github.com/cloudwego/eino/schema"
    "github.com/ollama/ollama/api"
)

func main() {
    ctx := context.Background()

    // åˆå§‹åŒ–æ¨¡å‹
    model, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
       BaseURL: "http://localhost:11434",
       Timeout: 30 * time.Second,
       Model:   "llama2",
       Options: &api.Options{
          Temperature: 0.7,
          NumPredict:  100,
       },
    })
    if err != nil {
       panic(err)
    }

    // å‡†å¤‡æ¶ˆæ¯
    messages := []*schema.Message{
       schema.SystemMessage("ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"),
       schema.UserMessage("ä»‹ç»ä¸€ä¸‹ Ollama"),
    }

    // ç”Ÿæˆå›å¤
    response, err := model.Generate(ctx, messages)
    if err != nil {
       panic(err)
    }

    // å¤„ç†å›å¤
    println(response.Content)
}
```

#### **æµå¼å¯¹è¯**

```go
package main

import (
    "context"
    "time"
    
    "github.com/cloudwego/eino-ext/components/model/ollama"
    "github.com/cloudwego/eino/schema"
)

func main() {
    ctx := context.Background()
    
    // åˆå§‹åŒ–æ¨¡å‹
    model, err := ollama.NewChatModel(ctx, &ollama.ChatModelConfig{
        BaseURL:  "http://localhost:11434",
        Timeout:  30 * time.Second,
        Model:    "llama2",
    })
    if err != nil {
        panic(err)
    }
    
    // å‡†å¤‡æ¶ˆæ¯
    messages := []*schema.Message{
        schema.SystemMessage("ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"),
        schema.UserMessage("è®²ä¸ªç¬‘è¯"),
    }
    
    // è·å–æµå¼å›å¤
    stream, err := model.Stream(ctx, messages)
    if err != nil {
        panic(err)
    }
    defer stream.Close() // æ³¨æ„å…³é—­ reader
    
    // å¤„ç†æµå¼å†…å®¹
    for {
        chunk, err := stream.Recv()
        if err != nil {
            break
        }
        print(chunk.Content)
    }
}
```

### [æ›´å¤šç¤ºä¾‹](https://github.com/cloudwego/eino-ext/tree/main/components/model/ollama/examples)

## **ç›¸å…³æ–‡æ¡£**

- [[ğŸš§]Eino: ChatModel ä½¿ç”¨è¯´æ˜](/zh/docs/eino/core_modules/components/chat_model_guide)
- [[ğŸš§]ChatModel - OpenAI](/zh/docs/eino/ecosystem_integration/chat_model/chat_model_openai)
- [[ğŸš§]Eino: ToolsNode ä½¿ç”¨è¯´æ˜](/zh/docs/eino/core_modules/components/tools_node_guide)
- [Ollama æ¨¡å‹åº“](https://ollama.ai/library)
